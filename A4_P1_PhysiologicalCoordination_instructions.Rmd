---
title: "Assignment 4 - Heart rate, respiration and interpersonal coordination"
author: "Sofie Ditmer"
date: "August 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 4 - Heart rate, respiration and interpersonal coordination

Physiological data (here heart rate [variability], and respiration) are increasingly popular. Historically treated as pernicious noise to be regressed out of neuro-imaging data, there is now increasing research on how these signals tell us something important about cognition and beyond being just a signal of cognitive processes also impact them in interesting ways. Advanced sport science, and the quantified self movement (closely followed by marketing and communication) have hailed continuous physiological tracking as a powerful way to access and modify attitudes, habits, and performance. Further, as team coordination (in the military, in decision processes and organizational contexts) is more and more in focus, research has attempted to measure how interpersonal coordination between physiological systems might tell us something important about e.g. emotional and cognitive coordination. See references in the reading list for more on this.

In this assignment, you will learn to:
- collect physiological data
- pre-process physiological data (and grow further your mad R skills)
- model the continuous interdependence between two signals (using a multilevel model as proxy for a dynamical system approach)
- conservatively assess the presence of coordination between to signals in a controlled context

This assignment has two parts. The first part familiarizes you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

3) Do you observe differences in coordination between conditions? Report the models and results.

4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.

N.B. to give you a bit more data I included data from previous years (Study1, Study2 and Study 3). Note that synchronouns and turn-taking are the same across both studies, but the third condition is different: in the first year it was self-paced joint reading; in the second year it was the tv-series conversation.

## Let's get started

### Exploring physiological signals

- Choose one pair (one pair, three conditions)
- Load the logs
- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal.
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() function allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3). There are also smarter packages, like cowplot and ggpubr.
- Can you eye-ball which condition if any displays more physiological coordination?

### First we read one data file and identify the procedure
- Load the file
- correctly identify all columns
- plot the data
- deal with the artifacts
- downsample the dat
- Add a column for study, group, trial and condition

```{r}
# Load the libraries
library(pacman)
pacman::p_load(tidyverse, dplyr, purrr, lme4, lmerTest, DescTools, sjstats, tidymodels, groupdata2, cvms, randomForest, ggplot2, caret, stats, quantmod)

# Load the file
single_file <- read.csv("data/Study1_G1_T1_Synchronous.csv")

##PLOT DATA##
#Plot: Heart Rate
plot1_HR <- ggplot(single_file, aes(x = time, y = HR1)) + geom_line()
plot1_HR

plot2_HR <- ggplot(single_file, aes(x = time, y = HR2)) + geom_line()
plot2_HR

#We use grid.arrange() function to show the plots next to each other
single_plots_HR <- gridExtra::grid.arrange(plot1_HR, plot2_HR, ncol = 2)

#Plot: Respiration
plot1_Resp <- ggplot(single_file, aes(x = time, y = Resp1)) + geom_line()
plot1_Resp

plot2_Resp <- ggplot(single_file, aes(x = time, y = Resp1)) + geom_line()
plot2_Resp

#We use grid.arrange() function to show the plots next to each other
single_plots_Resp <- gridExtra::grid.arrange(plot1_Resp, plot2_Resp, ncol = 2)

```

```{r}
##REMOVE OUTLIERS##
#We set the threshold to 2.5 standard deviations, which means that we remove all data points above or below 2.5

#First we create a function that removes outliers
removeOuts <- function(ts,threshold){
  ts[ts > (mean(ts,na.rm=T) + (threshold*sd(ts,na.rm=T)))] = mean(ts,na.rm=T) +
             (threshold*sd(ts,na.rm=T))
  ts[ts < (mean(ts,na.rm=T) - (threshold*sd(ts,na.rm=T)))] = mean(ts,na.rm=T) -
             (threshold*sd(ts,na.rm=T))
  return(ts)
}
threshold=2.5 # Default value at 2.5 sds from the mean

#Removing outliers: Heart rate 
single_file$HR1_clean <- removeOuts(single_file$HR1, 2.5)
single_file$HR2_clean <- removeOuts(single_file$HR2, 2.5)

#Removing outliers: Respiration
single_file$Resp1_clean <- removeOuts(single_file$Resp1, 2.5)
single_file$Resp2_clean <- removeOuts(single_file$Resp2, 2.5)


#Now we plot the raw data againt those with the artiacts (outliers) removed. We want to have multiple plots showing the raw and the clean data for each participant. First we make a new dataframe selecting only the columns we want.

select_single_file <- select(single_file, time, HR1, HR1_clean, HR2, HR2_clean, Resp1, Resp2, Resp1_clean, Resp2_clean)  

#HEART RATE#
#Now we use the gather function to merge the raw HR1 data and the clean HR1 data which means that we do not want the HR2 and the HR2_clean data to be combined which is why we put them inside the -c()

select_single_file <- gather(select_single_file, "HR1", "HR1_raw_and_HR1_clean", -c(time, HR2, HR2_clean, Resp1, Resp2, Resp1_clean, Resp2_clean))

#Now we use the gather function to merge the raw HR2 data and the clean HR2 data which means that we do not want the HR1 and the HR1_clean data to be combined which is why we put them inside the -c()

select_single_file <- gather(select_single_file, "HR2", "HR2_raw_and_HR2_clean", -c(time, HR1, HR1_raw_and_HR1_clean, Resp1, Resp2, Resp1_clean, Resp2_clean))

#Now we can plot the HR1 and HR2 data
plot_HR1 <- ggplot(select_single_file, aes(x = time, y = HR1_raw_and_HR1_clean, color = HR1)) +
  geom_line() + 
  labs(title = "HR1", x = "time", y = "Heart Rate")

plot_HR1

plot_HR2 <- ggplot(select_single_file, aes(x = time, y = HR2_raw_and_HR2_clean, color = HR2)) + 
  geom_line() + 
  labs(title = "HR2", x = "time", y = "Heart Rate")

plot_HR2

#Using grid.arrange function to plot the two next to each other
plots_HR <- gridExtra::grid.arrange(plot_HR1, plot_HR2, ncol = 2)

#RESPIRATION#
#Using gather function in the same way as we did for the heart rate data
select_single_file <- gather(select_single_file, "Resp1", "Resp1_raw_and_Resp1_clean", -c(time, Resp2, Resp2_clean, HR2_raw_and_HR2_clean, HR1_raw_and_HR1_clean, HR1, HR2))

select_single_file <- gather(select_single_file, "Resp2", "Resp2_raw_and_Resp2_clean", -c(time, Resp1, Resp1_raw_and_Resp1_clean, HR2_raw_and_HR2_clean, HR1_raw_and_HR1_clean, HR1, HR2))

#Now we plot the respiration data
plot_Resp1 <- ggplot(select_single_file, aes(x = time, y = Resp1_raw_and_Resp1_clean, color = Resp1)) +
  geom_line() + 
  labs(title = "Respiration 1", x = "Time", y = "Heart Rate")

plot_Resp1

plot_Resp2 <- ggplot(select_single_file, aes(x = time, y = Resp2_raw_and_Resp2_clean, color = Resp2)) +
  geom_line() + 
  labs(title = "Respiration 2", x = "Time", y = "Heart Rate")

plot_Resp2

#Using grid.arrange function to plot the two next to each other
plots_Resp <- gridExtra::grid.arrange(plot_Resp1, plot_Resp2, ncol = 2)


```

```{r}
##SCALE##
#First we scale the heart rate data and then we scale the respiration data

#HEART RATE##
#First we create a new column for the scaled heart rates for both HR1 and HR2
single_file$HR1_scaled <- scale(single_file$HR1_clean)
single_file$HR2_scaled <- scale(single_file$HR2_clean)

#Now we plot again to check what the scaled data look like
plot1_HR_scaled <- ggplot(single_file, aes(x = time, y = HR1_scaled)) + 
  geom_line() + 
  labs(title = "HR1", x = "Time", y = "Heart Rate")

plot1_HR_scaled

plot2_HR_scaled <- ggplot(single_file, aes(x = time, y = HR2_scaled)) + 
  geom_line() + 
  labs(title = "HR2", x = "Time", y = "Heart Rate")

plot2_HR_scaled

#Using the grid.arrange function to plot the two next to each other
single_plots_HR_scaled <- gridExtra::grid.arrange(plot1_HR_scaled, plot2_HR_scaled, ncol = 2)


##RESPIRATION##
#Now we scale the respiration data
single_file$Resp1_scaled <- scale(single_file$Resp1_clean)
single_file$Resp2_scaled <- scale(single_file$Resp2_clean)

#Now we plot again to check what the scaled respiration data look like
plot1_respiration_scaled <- ggplot(single_file, aes(x = time, y = Resp1_scaled)) + 
  geom_line() + 
  labs(title = "Respiration 1", x = "Time", y = "Respiration")

plot1_respiration_scaled

plot2_respiration_scaled <- ggplot(single_file, aes(x = time, y = Resp2_scaled)) + 
  geom_line() + 
  labs(title = "Respiration 2", x = "Time", y = "Respiration")

plot2_respiration_scaled

#Using the grid.arrange function to plot them next to each other
single_plots_resp_scaled <- gridExtra::grid.arrange(plot1_respiration_scaled, plot2_respiration_scaled, ncol = 2)
```

```{r}
##DOWNSAMPLE##
#First we create a new column named "rownames" which is used as an index to put the columns back together later
single_file$rownames <- (1:nrow(single_file))

#Now we downsample using Kenneth's code
d1 = single_file %>%
 group(n = 100, method = 'greedy') %>%
 dplyr::summarise(
   time = mean(time,na.rm=T),
   HR1 = mean(HR1_scaled,na.rm=T),
   HR2 = mean(HR2_scaled,na.rm=T),
   Resp1 = mean(Resp1_scaled,na.rm=T),
   Resp2 = mean(Resp2_scaled,na.rm=T),
   rowname = rownames[1]) #the index we use to put them back together

#Now we plot the downsampled data
p4 <- ggplot(data = d1) +
  geom_path(aes(time, Resp1, color = "Respiration 1")) +
  geom_path(aes(time, Resp2, color = "Respiration 2")) +
  labs(x = "Time", y = "Resp") +
  theme(legend.position="bottom")

p4

p5 <- ggplot(data = d1) +
  geom_path(aes(time, HR1, color = "Heart Rate1")) +
  geom_path(aes(time, HR2, color = "Hear Rate 2")) +
  labs(x = "Time", y = "Heart Rate") +
  theme(legend.position="bottom")

p5

```

## Now we are ready to go to load and pre-process all files

Go through all the files (with a function passed onto map_df), check which files should be excluded, if any, and save the pre-processed time-series

A couple of tips:
- looping is oh so slow. Making a function and using Map/Map_df is your salvation.
- each study restarts the group numbering, so you should make sure to change that (e.g. 100 * Study + Group)
- you need to make sure all the data are meaningful or something has to be removed. Plotting is your friend. E.g. "Study1_G1_T1_Synchronous" has one bad respiration signal. We could replace it with NAs

```{r}
##PREPROCESSING##
#We create a function that splits up the filenames, removes artifacts, scales, and downsamples.
data_preprocess <- function(filename, threshold = 2.5){
  
  df <- read.csv(filename)
  
  #First we remove outliers
  #Heart rate: removing outliers
  df$HR1_clean <- removeOuts(df$HR1, 2.5)
  df$HR2_clean <- removeOuts(df$HR2, 2.5)
  
  #Respiration: removing outliers
  df$Resp1_clean <- removeOuts(df$Resp1, 2.5)
  df$Resp2_clean <- removeOuts(df$Resp2, 2.5)
  
  #Now we scale
  #Heart rate: scaling
  df$HR1_scaled <- scale(df$HR1_clean)
  df$HR2_scaled <- scale(df$HR2_clean)
  
  #Respiration: scaling
  df$Resp1_scaled <- scale(df$Resp1_clean)
  df$Resp2_scaled <- scale(df$Resp2_clean)
  
  #Downsampling
  df$rownames <- (1:nrow(df))
  
  t <- str_split(filename, "G", simplify = TRUE) 
  st <- str_extract(t[1], "\\d") 
  
  if (st == "4"){ #In study 4 the time-column is called "TimeMs" which is different from all other studies. Therefore we tell the function to name the column "time" instead of "TimeMs" for study 4
    df <- df %>% rename(
      time = TimeMs
    )
  }
  
  d1 = df %>%
    group(n = 1000, method = 'greedy') %>%
    dplyr::summarise(
      time = mean(time,na.rm=T),
      HR1 = mean(HR1_scaled,na.rm=T),
      HR2 = mean(HR2_scaled,na.rm=T),
      Resp1 = mean(Resp1_scaled,na.rm=T),
      Resp2 = mean(Resp2_scaled,na.rm=T),
      File =filename,
      rowname = rownames[1]) #the index we use to put them back together
  
  #Now we need to split the whole file name before "G" so we can get the study
  t <- str_split(filename, "G", simplify = TRUE) #this will split the filename before "G". G dissapears when we split
  
  st <- str_extract(t[1], "\\d") #//d means that we only want numerics - thus we remove characters
  st <- as.numeric(st)
  d1$Study<- st #Here we add a new colum called "Study" to the dataframe d1
  
  #Now we want to get the group extracted from the filename, so we split up before T    
  g <- str_split(t[2], "T", simplify = TRUE) #this will split the filename before "T"
  gr <- str_extract(g[1], "\\d")
  gr <- as.numeric(gr)
  d1$Group <- gr #we add a new column to the dataframe
  
  #Now we want the condition
  co <- str_split(filename, "_", simplify = TRUE) # split before period
  con <- str_split(co[,4], "[[:punct:]]", simplify = TRUE)#we split before underscore
  con_2 <- con[,1]
  d1$Condition <- con_2 #adding condition as a colum in the dataframe d1
  
  #Now we want the trial   
  tr <- str_split(co[,3], "T", simplify = TRUE)
  tr_1 <- tr[,2]
  d1$Trial <- tr_1 #adding trial as a column

  return(d1)

}

#We apply this function on a single file to test if it works
test_data <- data_preprocess("data/Study1_G1_T2_TurnTaking.csv")

#Now we can run the functions on the whole dataset using map_df
phys_data = list.files(path = "data/", pattern = ".csv", full.names = T) %>%
    purrr::map_df(data_preprocess)

#Now we need to make sure all the data are meaningful or something has to be removed
#E.g."Study1_G1_T1_Synchronous" has one bad respiration signal. We could replace it with NAs

#We turn everything into ms and not seconds using an ifelse statement
phys_data$time <- ifelse(phys_data$Study == 1, phys_data$time*1000, phys_data$time)
phys_data$time <- ifelse(phys_data$Study == 2, phys_data$time*1000, phys_data$time)
phys_data$time <- ifelse(phys_data$Study == 4, phys_data$time*1000, phys_data$time)

#We make Group, Study, and Trial into factors
phys_data$Group <- as.factor(phys_data$Group)
phys_data$Study <- as.factor(phys_data$Study)
phys_data$Trial <- as.factor(phys_data$Trial)

##PLOTTING: HEART RATE##
#Now we plot the data
plot_phys_resp <- ggplot(data = phys_data) +
  geom_path(aes(time, Resp2)) +
  labs(x = "Time", y = "Resp") +
  theme(legend.position="bottom") +
  facet_wrap(phys_data$Study == 1|2)

plot_phys_resp

plot_phys_HR <- ggplot(data = phys_data) +
  geom_path(aes(time, HR1, color = File)) +
  geom_path(aes(time, HR2, color = File)) +
  labs(x = "Time", y = "Heart Rate") +
  theme(legend.position="bottom") +
  facet_wrap(phys_data$Study)

plot_phys_HR

#We see that the file S1_G1_T1_TurnTaking.csv has bad data and we have to remove it using the function that removes outliers that we made previously
phys_data_clean <- phys_data #Making a new dataframe for our clean data

#Removing outliers 
phys_data_clean$HR2 <- removeOuts(phys_data_clean$HR2, 2.5)
phys_data_clean$HR1 <- removeOuts(phys_data_clean$HR1, 2.5)
phys_data_clean$Resp1 <- removeOuts(phys_data_clean$Resp1, 2.5)
phys_data_clean$Resp2 <- removeOuts(phys_data_clean$Resp2, 2.5)

plot_phys_resp <- ggplot(data = phys_data_clean) +
  geom_path(aes(time, Resp1, color = Study)) +
  geom_path(aes(time, Resp2, color = Study)) +
  labs(x = "Time", y = "Resp") +
  theme(legend.position="bottom")

plot_phys_resp

plot_phys_HR <- ggplot(data = phys_data_clean) +
  geom_path(aes(time, HR1, color = Study)) +
  geom_path(aes(time, HR2, color = Study)) +
  labs(x = "Time", y = "Heart Rate") +
  theme(legend.position="bottom") +
  facet_wrap(phys_data_clean$Study == 1|2) #

plot_phys_HR

##ASSESSING BAD DATA##
#Remove bad data. We need to remove the flat signals in the data for both heart rate and respiration. In order to get a feel of where the bad data is (the flat signal) we plot the data one study at a time.
#We only look at Heart rate because that is the only data we are going to analyze.

#We plot the raw data and the clean data for all studies

#First we look at study 1
d1_raw <- filter(phys_data, Study == 1)

d1_raw <- group_by(d1_raw, Group, Trial) %>% 
  mutate(time1 = seq(n())) #mutate creates a new column, time1, and seq() starts over each time

ggplot(data = d1_raw) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

d1_clean <- filter(phys_data_clean, Study == 1)

d1_clean <- group_by(d1_clean, Group, Trial) %>% 
  mutate(time1 = seq(n())) #mutate creates a new column, time1, and seq() starts over each time

ggplot(data = d1_clean) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

#When you look at the plot, the first number (top number) is the group and the second number (bottom number) is trial

#When we look at the data from study 1 there is no flat lining, which is good

#Now we look at study 2
d2_raw <- filter(phys_data, Study == 2)

d2_raw <- group_by(d2_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d2_raw) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

d2_clean <- filter(phys_data_clean, Study == 2)

d2_clean <- group_by(d2_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d2_clean) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

#In this plot (study 2) we can see that there is flat linining in group 6, trial 3 and an artefact in group 9, trial 1. We need to assign NAs to these bad signals.

#Now we look at study 3
d3_raw <- filter(phys_data, Study == 3)

d3_raw <- group_by(d3_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d3_raw) + geom_line(aes(time1, HR1, color= "red")) +
  xlim(0,250) +
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

d3_clean <- filter(phys_data_clean, Study == 3)

d3_clean <- group_by(d3_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d3_clean) + geom_line(aes(time1, HR1, color= "red")) + 
  xlim(0,250) +
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

#When we look at study 3 it all looks good.

#Now we look at study 4
d4_raw <- filter(phys_data, Study == 4)

d4_raw <- group_by(d4_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d4_raw) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

d4_clean <- filter(phys_data_clean, Study == 4)

d4_clean <- group_by(d4_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d4_clean) + geom_line(aes(time1, HR1, color= "red")) + 
  geom_line(aes(time1, HR2, color= "blue")) + 
  facet_wrap(Group~Trial)

#When we look at study 4 it all looks good.

#We should be careful to remove good data - the solution is to replace bad data with NA and then remove the NAs. When we report, we should remember to count the number of participants - the number that the count function gives us is not the actual number, because we have removed the data from the participants with NAs.

##REMOVING BAD DATA: HEART RATE##
#We replace the bad signalS with NAs for a particular study, group, trial, condition etc.

#First we make a dataframe containing the data from the study where the bad signal is (this is in study 2, group 6 and trial 3)
phys_data_bad <- filter(phys_data_clean, Study == 2, Group == 6, Trial == 3)

#Now we plot the data so we are able to see in which time interval this bad data is in
ggplot(data = phys_data_bad) + geom_line(aes(time, HR1, color= "red")) +
  geom_line(aes(time, HR2, color= "blue")) 

#We can see that the bad signal start at 24200 and ends at 26600. This is where we need to replace the signal with NAs. Thus, we replace this internal with NAs because this is bad data.
phys_data_clean$HR2[phys_data_clean$Study == 2 & phys_data_clean$Group == 6 & phys_data_clean$Trial == 3 & phys_data_clean$time > 24200 & phys_data_clean$time < 26600] <- NA

#There is also a bad signal in study 2, group 9, trial 1. We make a dataframe containing the data from this specific study, group and trial.
phys_data_bad <- filter(phys_data_clean, Study == 2, Group == 9, Trial == 1)

#Now we plot the data so we are able to see in which time interval this bad data is in
ggplot(data = phys_data_bad) + geom_line(aes(time, HR1, color= "red")) +
  geom_line(aes(time, HR2, color= "blue")) 

#We can see that the bad signal start at 0 and ends at 1000. This is where we need to replace the signal with NAs. Thus, we replace this internal with NAs because this is bad data.
phys_data_clean$HR2[phys_data_clean$Study == 2 & phys_data_clean$Group == 9 & phys_data_clean$Trial == 1 & phys_data_clean$time > 0 & phys_data_clean$time < 1000] <- NA

##PLOTTING: RESPIRATION##
#We plot the raw data and the clean data for all studies

#First we look at study 1
d1_raw <- filter(phys_data, Study == 1)

d1_raw <- group_by(d1_raw, Group, Trial) %>% 
  mutate(time1 = seq(n())) #mutate creates a new column, time1, and seq() starts over each time

ggplot(data = d1_raw) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

d1_clean <- filter(phys_data_clean, Study == 1)

d1_clean <- group_by(d1_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d1_clean) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

#We can see that there is a lot of bad signals. We need to assign NAs to these.

#Now we look at study 2
d2_raw <- filter(phys_data, Study == 2)

d2_raw <- group_by(d2_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d2_raw) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

d2_clean <- filter(phys_data_clean, Study == 2)

d2_clean <- group_by(d2_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d2_clean) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

#Now we look at study 3
d3_raw <- filter(phys_data, Study == 3)

d3_raw <- group_by(d3_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d3_raw) + geom_line(aes(time1, Resp1, color= "red")) +
  xlim(0,250) +
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

d3_clean <- filter(phys_data_clean, Study == 3)

d3_clean <- group_by(d3_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d3_clean) + geom_line(aes(time1, Resp1, color= "red")) + 
  xlim(0,250) +
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

#Now we look at study 4
d4_raw <- filter(phys_data, Study == 4)

d4_raw <- group_by(d4_raw, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d4_raw) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

d4_clean <- filter(phys_data_clean, Study == 4)

d4_clean <- group_by(d4_clean, Group, Trial) %>% 
  mutate(time1 = seq(n()))

ggplot(data = d4_clean) + geom_line(aes(time1, Resp1, color= "red")) + 
  geom_line(aes(time1, Resp2, color= "blue")) + 
  facet_wrap(Group~Trial)

##REMOVING BAD DATA: RESPIRATION##
#Study 1
phys_data_clean$Resp1[phys_data_clean$Study == 1 & phys_data_clean$Group == 1 & phys_data_clean$Trial == 1] <- NA #study 1, group 1, trial 1

phys_data_clean$Resp1[phys_data_clean$Study == 1 & phys_data_clean$Group == 1 & phys_data_clean$Trial == 2] <- NA #study 1, group 1, trial 2

phys_data_clean$Resp2[phys_data_clean$Study == 1 & phys_data_clean$Group == 2 & phys_data_clean$Trial == 1] <- NA #study 1, group 2, trial 1

phys_data_clean$Resp2[phys_data_clean$Study == 1 & phys_data_clean$Group == 2 & phys_data_clean$Trial == 2] <- NA #study 1, group 2, trial 2

#In study 3, group 2, trial 2, there is a flatlining that we need to remove. We need to plot it first in order to see in which time interval it is in. 
phys_data_bad <- filter(phys_data_clean, Study == 3, Group == 9, Trial == 2)

#Now we plot the data so we are able to see in which time interval this bad data (flatlining) is in
ggplot(data = phys_data_bad) + geom_line(aes(time, Resp1, color= "red")) +
  geom_line(aes(time, HR2, color= "blue")) 

#Now that we can see in which interval the flat signal is in we can replace the interval with NAs
phys_data_clean$Resp1[phys_data_clean$Study == 3 & phys_data_clean$Group == 9 & phys_data_clean$Trial == 2 & phys_data_clean$time > 2330000 & phys_data_clean$time < 2550000] <- NA

#Save the data into a csv-file
write.csv(phys_data_clean, file = "physiological_data.csv")

```

## Now we need to run some analysis

Let's start with a multilevel model that accounts for 
- stability (how each signal is autocorrelated)
- interpersonal dependence (each signal is dependent from the previous state of the other signal)

The data needs to be further prepared, so we can analyze both participants in the same model.
We need to turn the data into a long format:
- a column indicating own HR and one own respiration
- a column indicating other HR and one other respiration
- a column indicating change in HR from previous round and one in respiration

We can then run an analysis where change is a function of one's previous state (stability, see slides), and the other's previous state (coupling). Make sure to:
- set up the most interesting contrasts: how do these parameters vary by condition? which condition should be baseline?
- set up the right random effects.
- N.B. the model will be slow. Make sure it works on a subset of the data first!

Bonus question: what if we include an additional layer? Is my heart rate just adjusting to yours, or also to how much you are adjusting to mine?
- to start answering this we can add a column indicating the previous change in hr in the other and one in respiration
- we can then build on the previous models by also adding the previous change in the other

##NOTES FROM CLASS##
Now that we have cleaned the data and preprocessed it we can now make a model. We take the modelS from the paper and try to understand it and write it up in a way that is more simple to us. These are the models/equations from the paper:

Participant 1:
dx/dt = a1(x* - xt) + a2(yt - x*)

Participant 2:
dy/dt = b1(y* - yt) + b2 (xt - y*)

The equations describe change. How things change over time:

- dx means that "change of x" over the "change of time". Thus, we look at how heart rate changes from t0 to t1 - this could also be writte as ∆HR1 in the first equation (participant 1) and ∆HR2 in the second equation (participant 2). 

- a1 is a parameter that needs to be estimated, while xt is the heart rate at a given time (baseline). Thus, a1 is a beta-value.

- x* is the baseline reference (the mean which is set to 0). Thus, the x* in the equations are 0, which means that we can just remove them from the equation.

Remember that stability, how our own heart rate is dependent on itself, is negative if it gets pulled towards the reference, which means that the higher the heart rate is compared to the reference the more it is being pulled towards the reference. Negative stability is "stable" (moving towards the reference), and postive stability is "unstable"  (moving away from the reference). Therefore, we need a minus infront of the HR1 (we could also remove this minus, but then we would have to remember to interpret the beta in the opposite way). Beta is the slope, the change from baseline, and if it is postive it moves away from the reference which results in a heart rate that moves away from the reference and vice versa. A stable (negative) beta means that the heart rate will move closer to the baseline, while an unstable (positive) beta means that heart rate will move away from the baseline.

Thus, we can simplify the equation and write it like this:

y ~ b1(- HR1) + b2(HR2)

If we remove the minus in front of HR1 we need to just keep it in mind when we interpret the values. 
When we take lmer (because the outcome is "change" we use lmer and not glmer because the outcome is not categorical but numeric. Change is a continous variable and therefore we use lmer and not glmer). 

y ~ b1(HR1) + b2(HR2)

Now we use lmer:
lmer(∆HR1 ~ HR1 + HR2) #this says that change in HR1 is a function of HR1 plus HR2

We fit the model and get an output. HR1 (stability) and HR2 (coupling) are two parameters. Thus, the higher the heart rate goes in person 2, the higher the heart goes in person 1. The higher the heart rate of person 1 (stability) the higher the heart rate is going to go (positive beta) which means that the more it moves away from the baseline/reference, BUT remember that there is actually a minus sign infront of the HR1 which means that it is actually the other way around - the higher the heart rate in person 1 (stability) the more the heart rate will move towards the baseline (negative beta).

We want to estimate the same parameters for both participant 1 and participant 2. Therefore we do multilevel modeliing - all the data from participant 1 and all the data from participant 2 in a long format dataframe. Thus, we jsut use one equation in a multilevel model, and therefore we estimate the parameters for both participants just using one equation in a multilevel model. Thus, our model now looks like:

lmer(∆HRp ~ HRp + HRo)

Now our equation does not specify a certain participant but it can be used for both participant 1 and 2.

There is an equation that describes that two pendulums over time move out of sync. This equation is very complex, but we can turn this equation into a lmer - a linear model. It describes "acceleration" in change (second derivative) - how fast you are changing the change. The change in change is the heart rate at time2 minus the heart rate at time 1. This tells us about the acceleration of the heart rate (the change of the change). 

Thus, we turn the complex equation into a simple lmer model:

∆∆HR1 ~ -b1∆HR1 - b2HR1 - b3HR2 

We can remove the minus signs and instead write -1 in the end:

∆∆HR1 ~ b1∆HR1 + b2HR1 + b3HR2 -1

NB! ∆∆HR1 is a change in change (acceleration). It could also be written as y. 


This is the model we want to fit:

lmer(HR - change ~ HR + HRother)

We do not want two equations, one for each participant, for two reasons:
1. We want to keep things simple
2. We can do partial pooling when we only have one equation. 

The first thing we need to do is to calculate the HRchange - how much HR differs from the previous HR. This can be done using 

HR1_future/lead =  lead(HR1, 1) #1 is the delay/lag - which means that it shifts it one time point

Thus, we are creating a new column HR_lead which is shifted in time. We are doing this in order to subtract the previous HR from the lead/"future" heart rate. 

HR_change = HR1_lead - HR1

```{r}
#We are only going to do the analysis on study 4 (the data from our year).
phys_data_2019 <- filter(phys_data_clean, Study == 4)

#Genearate a column for each: lead HR1, HR2, Resp1, Resp2
phys_data_2019$HR1_lead <- lead(phys_data_2019$HR1, 1)

phys_data_2019$HR2_lead <- lead(phys_data_2019$HR2, 1)

phys_data_2019$Resp1_lead <- lead(phys_data_2019$Resp1, 1)

phys_data_2019$Resp2_lead <- lead(phys_data_2019$Resp2, 1)

#Genearate a column for each: change in HR1, HR2, Resp1, Resp2
phys_data_2019$HR1_change <- phys_data_2019$HR1_lead - phys_data_2019$HR1

phys_data_2019$HR2_change <- phys_data_2019$HR2_lead - phys_data_2019$HR2

phys_data_2019$Resp1_change <- phys_data_2019$Resp1_lead - phys_data_2019$Resp1

phys_data_2019$Resp2_change <- phys_data_2019$Resp2_lead - phys_data_2019$Resp2

#Make the data long, so we can analyze both participants at the same time 
#N.B. This is a bit tricky and you might have to do it in several steps

#We create the new columns (variables) that we need
HR_change_self <- 
  gather(phys_data_2019, #data
         participant, HR_change_self, #new vars
         HR1_change, HR2_change) %>% #old vars 
         select( #drop irrelevant vars
           time, HR_change_self, participant, Study, Group, Condition, Trial) %>%
           mutate( #create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

HR_change_other <- 
  gather(phys_data_2019, # data
         participant, HR_change_other, #new vars
         HR2_change, HR1_change) %>% #old vars 
         select( # drop irrelevant vars
           time, HR_change_other, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))
HR_self <- 
  gather(phys_data_2019, # data
         participant, HR_self, #new vars
         HR1, HR2) %>% #old vars 
         select( # drop irrelevant vars
           time, HR_self, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

HR_other <-
  phys_data_2019 %>%
  mutate(
    HR1o=HR2, #we use mutate to make sure that it takes HR2 before HR1
    HR2o=HR1
  ) %>%
  gather( # data
         participant, HR_other, # new vars 
         HR1o, HR2o) %>% #old vars
         select( # drop irrelevant vars
           time, HR_other, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

HR_lead <- 
  gather(phys_data_2019, # data
         participant, HR_lead, #new vars
         HR1_lead, HR2_lead) %>% #old vars 
         select( # drop irrelevant vars
           time, HR_lead, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

Resp_change_self <- 
  gather(phys_data_2019, # data
         participant, Resp_change_self, # new vars 
         Resp1_change, Resp2_change) %>% #old vars
         select( # drop irrelevant vars
           time, Resp_change_self, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

Resp_change_other <- 
  gather(phys_data_2019, # data
         participant, Resp_change_other, # new vars 
         Resp2_change, Resp1_change) %>% #old vars
         select( # drop irrelevant vars
           time, Resp_change_other, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

Resp_self <- 
  gather(phys_data_2019, # data
         participant, Resp_self, # new vars 
         Resp1, Resp2) %>% #old vars
         select( # drop irrelevant vars
           time, Resp_self, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

Resp_other <- 
  gather(phys_data_2019, # data
         participant, Resp_other, # new vars 
         Resp2, Resp1) %>% #old vars
         select( # drop irrelevant vars
           time, Resp_other, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

Resp_lead <- 
  gather(phys_data_2019, # data
         participant, Resp_lead, #new vars
         Resp1_lead, Resp2_lead) %>% #old vars 
         select( # drop irrelevant vars
           time, Resp_lead, participant, Study, Group, Condition, Trial) %>%
           mutate( # create unique participant ID
             participant = parse_number(as.character(Group)) * 10 +
               parse_number(participant))

#Now we merge them (we can only merge two at a time)
merged_data1 <- merge(HR_change_self, HR_change_other, all=T, by = c("time", "Study", "Trial", "Group", "participant", "Condition")) 

merged_data2 <- merge(HR_self, HR_other, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

merged_data3 <- merge(HR_lead, Resp_change_self, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

merged_data4 <- merge(Resp_change_other, Resp_self, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

merged_data5 <- merge(Resp_other, Resp_lead, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

phys_data_long1 <- merge(merged_data1, merged_data2, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition" ))

phys_data_long2 <- merge(phys_data_long1, merged_data3, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

phys_data_long3 <- merge(phys_data_long2, merged_data4, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

phys_data_long <- merge(phys_data_long3, merged_data5, all = T, by = c("time", "Study", "Trial", "Group", "participant", "Condition"))

#We set the most interesting contrast e.g. by defining the baseline. We set the baseline to "movementguided"
phys_data_long$Condition <- as.factor(phys_data_long$Condition)
phys_data_long$Condition <- relevel(phys_data_long$Condition, ref="MovementGuided")

#We create a model looking at heart rate change as a function of own and other previous heart rate state
#Why are we modelling heart rate change instead of the future/lead heart rate?
#Answer: because biological and dynamic systems are about change. We look at the change compared to the previous state which allows us to investigate the stabilization and run-away effect - the further from the baseline the heart rate is, the change tells us if the heart rate is going to move further away from the baseline or closer to the baseline. We look at change in order to assess this. If we were to look at future heart rate instead, we would answer another question. 

model_1 <- lmer(HR_change_self ~ 0 + Condition + 
                (HR_self + HR_other) : Condition + 
                (0 + Condition|participant) + 
                (0 + Condition|Group), data = phys_data_long)

summary(model_1)

#We make the model using * in order to check the significance of the coupling-parameters
model_2 <- lmer(HR_change_self ~ 0 + Condition + 
                (HR_self + HR_other) * Condition + 
                  (0 + Condition|participant) + 
                  (0 + Condition|Group), data = phys_data_long)

summary(model_2)

#Note that our model is saying that whenever HR_self is above baseline, HR_other will also be pulled away from baseline. 

##Looking at the output of the model##
#HR_self is stability
#HR_other is coupling

#We can see that all slopes with HR_self are significant, which means that for each condition the heart rate for self (HR_self) is stabil. This value is negative in the output, but remember that we have a minus to include (which we chose to not have in the model and just remember instead when we wanted to interpret the output), and this means that the value in the output is actually positive and not negative.

#Coupling (the conditions wiht :HR_other) is not significant, which means that the HR1 and HR2. 

#Bonus points: Add to the previous model also change in the other to see whether my adaptation is influenced by the other's adaptation.
```
##EXAPLANATION OF THE SYNTAX OF THE MODEL##

#FIXED/STRUCTURAL EFFECTS#
Stability: the beta of the HR_self
Coupling: the beta of the HR_other (the beta of the HR_other minus the HR_self)
Effects of condition: stability and coupling might differ across conditions. 

#INTERACTION EFFECTS#
In our model we say that the HR_self and HR_other interact with the condition - thus, the two people vary in their reaction to the different conditions. We model interaction effects in our model by using : instead of * because this will give us all of the conditions in the summary output and using * will not.
Because we have different individuals we need to account for this in our model. This means that we cannot expect that coupling and stability will be the same for all participants. Furthermore, we cannot expect that the effects of conditions are the same across all participants. We might see that in certain conditions the effects might become stronger. The way conditions changes the values of stability and coupling might vary across participants. Thus, we expect stability and coupling to vary across conditions.

The zero-notation:
By putting 0 in front of the fixed effects, we will get separate intercepts for the two groups (HR_self and HR_other). 0 tells the lmer to give us an intercept for each of the main effects. Because HR_self and HR_other are continous they cannot be the intercept, which is why it we write 0 + condition to get an intercept for each condition. We want to know what the effect (stability and coupling) of HR_self and HR_other is for each intercept in each condition. Thus, we write:

0 + condition + (HR_self + HR_other) : condition

"condition" is the intercepts
"(HR_self + HR_other) are the slopes

This model says that we have an intercept which is the condition we set as baseline, and then it is saying that when condition is the baseline and when HR_self and HR_other is zero it gives us the average level of change. We also have the effect of the HR_self (stability) in the baseline condition - this is the main effect of HR_self in the baseline condition when everything else is zero. We also have a main effect of HR_other (coupling) for the baseline condition.
The interaction effect is the difference between the effect of HR_self in the baseline condition and the effect of HR_self in the next condtiion. We are telling the model to give us the baseline change when HR_self and HR_other are zero in the three conditions (the three intercepts) and the three slopes for each condition.

When we use : instead of * we get the estimates for each condition (NB! the models are the same using * or : but the output is different). This might tell us that there is a significant different in stability and coupling for each condition. When using : it makes interpreting the intercepts much easier. When we use * it will give us the difference between the parameters.

We need to run the model both we colon and with the asterix because this will help us to interpret the interactions better. 

#VARYING/RANDOM EFFECTS#
We do not expect stability and coupling to be the same for each pair of participants, which is why we need to include random effects. We expect that the fixed effects and interaction effects will change according to the varying effects - by participant and also by the fact that two people are engaging with each other (the dyad/group). Thus, we expect the fixed effects to NOT be the same for each participant and for each pair - we expect them to vary which is what we tell the model by adding varying effects.

These are the random effects that we add:
(0 + Condition|participant) + (0 + Condition|Group)

We tell the model that the data are not all the same - some data are from pair 1 and pair 2 etc. The estimates of the effects should be constrained wihtin participants (random effect 1) and group (random effect 2). 

Partial pooling: we tell the model to keep in mind that there is another person in the pair - thus the data from participant 1 is informed by the data from participant 2. Thus, each participant is pulled towards the mean of all participants. 

The model is now very complex after adding the random effects - there are a lot of parameters (close to 1000 that the model needs to estimate which takes a long time). 
Therefore we need to simply the model - removing stability and coupling as individual level parameters :-(
We would not have to do this if we were doing Bayes, because in this framework we can tell the model were to look for the parameters it is estimating, which will make the process of estimating the parameters faster.

#THE BASELINES: SHUFFLED AND SURROGATE PAIRS##
Surrogate pairs: taking all of the pairs in study four, and creating all possible surrogate pairs (all the different ways in which one person from one pair can be combined with another person from a different pair). 

We want to know if our model (the intercepts and the slopes) changes by type (real vs. surrogate) - are we really seeing something that is due to actual coordination or just an effect that is due to the task. 
If the effect is due to the task, it will be the same no matter the type (real or surrogate)
For conversation we would expect that the effect is different according to type (real vs. surrogate). Therfore we add "type" to the model before the random effects: 

0 + (condition + (HR_self + HR_other) : condition) : Type + 
(0 + condition|participant) + 
(0 + condition|group)

## Now we need to create control baselines.

First shuffled controls, then surrogate pairs.

### Creating controls: shuffled controls

Shuffled controls break the temporal dependencies of time-series by shuffling the value within one time-series. This ensures the "coordination" observed is not due to the actual values in the series and not their sequence.
Tip: sample() is your friend, but make sure to shuffle things within participant/condition and not throughout the whole dataset
 
```{r}
#Create a shuffled dataset
HR_self$HR_self <-  sample(HR_self$HR_self)

HR_other$HR_other <- sample(HR_other$HR_other)

HR_self$HR_lead <-  lead(HR_self$HR_self, 1)

HR_self$HR_change_self <- HR_self$HR_self - HR_self$HR_lead

HR_self$HR_other <- HR_other$HR_other

HR_self$Type <- "shuffle"

D = rbind(phys_data_long[,colnames(phys_data_long)[colnames(phys_data_long) %in% colnames(HR_self)]], HR_self)

#Now run model where you specify Type (real vs. shuffled) as an interaction effect 
model_shuffle <- lmer(HR_change_self ~ 0 + (Condition + (HR_self + HR_other) : Condition): Type + (0 + Condition|participant) + (0 + Condition|Group), data = D)

summary(model_shuffle)

```
 
### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair)

```{r}
#Identify unique pairs within a given study (to keep things manageable) and create list of possible surrogate pairs (e.g. individual 1 from pair 1 and individual 2 from pair 2)
#Starting from the wide format, create "surrogate" dataset with the data from surrogate pairs

Groups <- as.numeric(as.character(unique(phys_data_long$Group[phys_data_long$Study==4]))) # List all pairs

SurrogateList <- expand.grid(a = Groups, b = Groups) # Identify all possible combinations of 2 pairs

SurrogateList = subset(SurrogateList, a != b) # exclude combinations with identical pairs

#Create empty data frame
surrogate_df <- data.frame(matrix(ncol = 15, nrow = 0))

u <- c("time", "Study", "Trial", "Group", "participant", "Condition", "HR_change_self", "HR_change_other", "HR_self", "HR_lead", "Resp_change_self", "Resp_change_other", "Resp_self", "Resp_other", "Resp_lead")

colnames(surrogate_df) <- u

for (i in 1:nrow(SurrogateList)){ # loop through all combinations
  x <- subset(phys_data_long, Group==SurrogateList$a[i]) # subset data from the first pair
  y <- subset(phys_data_long, Group==SurrogateList$b[i]) # subset data from the second pair 
  group <- c(800 + ((1:4)*i)) # create new pair id
  
  for (co in c("Synchronous","TurnTaking","MovementGuided","Conversation", "MovementCoop")){ # loop through conditions
    if (co %in% unique(x$Condition) & co %in% unique(y$Condition)){ # check that both pairs have the data for that condition
      z1 <- subset(x, Condition==co) # subset only that condtion from first pair
      z2 <- subset(y, Condition==co) # subset only that condtion from second pair

      if (nrow(z1) > nrow(z2)) { # make sure data have same length in both pairs
        z1<-z1[1:length(z2)]
        }
      
      if (nrow(z2) > nrow(z1)) {
        z2<-z2[1:length(z1)]
        }

       w1 <- z1 %>% mutate( # assemble new pair combining the 2 pairs
        HR2 = z2$HR2,
        Resp2 = z2$Resp2,
        HR2_lead = z2$HR2_lead, 
        Resp2_lead = z2$Resp2_lead, 
        HR2_change = z2$HR2_change,
        Resp2_change = z2$Resp2_change)
       
       surrogate_df <- rbind(surrogate_df, w1)
    } }}

#We make a column calling it "Type" in the two dataframes. 
surrogate_df$Type <- "surrogate"

phys_data_long$Type <- "real"

#Now we need to rbind the surrgate dataframe with the original data frame
phys_data_type <- rbind(phys_data_long, surrogate_df)

#Create models as in chunks above, but adding an interaction with the Real vs. Surrogate variable (exclude shuffled ones for simplicity)
model <- lmer(HR_change_self ~ 0 + 
                (Condition + (HR_self + HR_other) : Condition): Type + 
                (0 + Condition|participant) + 
                (0 + Condition|Group), data = phys_data_type)

summary(model)

```
 

### Effects of respiration coordination on heart rate coordination
 - describe how you would test those.
 - Optional: run the models and report them

 